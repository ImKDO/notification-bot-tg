services:
    broker:

        image: apache/kafka:latest
        container_name: broker
        ports:
        - "9092:9092"
        environment:
            KAFKA_NODE_ID: 1
            KAFKA_PROCESS_ROLES: broker,controller
            
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://localhost:9093
            
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
            
            KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
            KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
            
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            KAFKA_NUM_PARTITIONS: 3
    
    redis:
        image: redis:7-alpine
        container_name: redis
        restart: always
        ports:
            - "6379:6379"
        volumes:
            - redis_data:/data
        command: redis-server --appendonly yes

    postgres:
        image: postgres:15
        container_name: postgres
        restart: always
        environment:
            POSTGRES_DB: notification_bot
            POSTGRES_USER: postgres
            POSTGRES_PASSWORD: postgres
        ports:
            - "5432:5432"
        volumes:
            - postgres_data:/var/lib/postgresql/data

    airflow:
        image: apache/airflow:2.9.3-python3.11
        container_name: airflow
        restart: always
        environment:
            AIRFLOW__CORE__EXECUTOR: LocalExecutor
            AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:postgres@postgres:5432/notification_bot
            AIRFLOW__CORE__FERNET_KEY: ""
            AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"
            AIRFLOW__CORE__LOAD_EXAMPLES: "false"
            AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"
            REDIS_URL: redis://redis:6379
            ML_SERVICE_URL: http://host.docker.internal:8042
            PARQUET_DIR: /opt/airflow/data/parquet
            _PIP_ADDITIONAL_REQUIREMENTS: "pyarrow>=17.0 redis>=5.0 httpx>=0.27 python-dotenv>=1.0"
        ports:
            - "8043:8080"
        volumes:
            - ./services/AirflowService/dags:/opt/airflow/dags
            - ./services/AirflowService/config.py:/opt/airflow/dags/config.py
            - ./services/AirflowService/arrow_utils.py:/opt/airflow/dags/arrow_utils.py
            - airflow_data:/opt/airflow/data
        depends_on:
            - postgres
            - redis
        command: airflow standalone

volumes:
    postgres_data:
    redis_data:
    airflow_data: